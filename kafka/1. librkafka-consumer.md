### librdkafka中consumer用法
近期接触kafka，使用了librdkafka(https://github.com/edenhill/librdkafka)作为client。    
librdkafa由c编写，同时也封装了cpp的client。封装的方法见:
    #include<librdkafka/rdkafkacpp.h>
关于consumer的使用，分high-level KafkaConsumer和 simple Consumer。   

#### 1. RdKafka::KafkaConsumer
KafkaConsumer使用起来较为方便，只需初始化KafkaConsumer、Conf,配置brokers、groupid、auto.offset.reset等字段就可以使用。
##### 1.1. Conf
CONF_GLOBAL // global configuration
CONF_TOPIC  // topic specific configuration
enable.auto.commit // true:consumer所fetch的消息的offset将会自动的同步到zookeeper。这项提交的offset将在进程挂掉时，由新的consumer使用   
auto.offset.reset // smallest: OFFSET_BEGINNING
                  // largest: OFFSET_END
group.id // groupid
metadata.brokers.list // brokers
partition // 可用RdKafka::TopicPartition，也可用制定parition, KafkaConsumer中使用RdKafka::RebalanceCB.

例子代码：
<pre><code>
#include &lt;librdkafka/rdkafkacpp.h>

class MyRebalanceCb : public RdKafka::RebalanceCb {
private:
  static void part_list_print (const std::vector<RdKafka::TopicPartition*>&partitions){
    for (unsigned int i = 0 ; i < partitions.size() ; i++)
      std::cerr << partitions[i]->topic() <<
    "[" << partitions[i]->partition() << "], ";
    std::cerr << "\n";
  }

public:
  void rebalance_cb (RdKafka::KafkaConsumer *consumer,
             RdKafka::ErrorCode err,
                     std::vector<RdKafka::TopicPartition*> &partitions) {
    std::cerr << "RebalanceCb: " << RdKafka::err2str(err) << ": ";

    part_list_print(partitions);

    if (err == RdKafka::ERR__ASSIGN_PARTITIONS)
    {
      consumer->assign(partitions);
    } else
    {
      consumer->unassign();
    }
  }
};

void msg_consume(RdKafka::Message* message, void* opaque)
{
    switch (message->err()) {
        case RdKafka::ERR__TIMED_OUT:
            break;

        case RdKafka::ERR_NO_ERROR:
        {
            // message from kafka
            string valStr(static_cast<char*>(message->payload()),
                static_cast<int>(message->len()));
        }
            break;

        case RdKafka::ERR__PARTITION_EOF:

            break;

        case RdKafka::ERR__UNKNOWN_TOPIC:
        case RdKafka::ERR__UNKNOWN_PARTITION:
            std::cerr << "Consume failed: " << message->errstr() << std::endl;
            break;

        default:
            std::cerr << "Consume failed: " << message->errstr() << std::endl;
    }
}

bool process(const string &topic_str, const string &brokers, const string &groupid)
{
    string errstr;
    int32_t partition = RdKafka::Topic::PARTITION_UA;

    std::vector<std::string> topics;
    topics.push_back(topic_str);

    RdKafka::Conf conf = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
    RdKafka::Conf tconf = RdKafka::Conf::create(RdKafka::Conf::CONF_TOPIC);

    conf->set("enable.auto.commit", "true", errstr);
    conf->set("metadata.broker.list", brokers, errstr);

    tconf->set("auto.offset.reset", "smallest",errstr);

    conf->set("default_topic_conf", tconf, errstr);

    MyRebalanceCb my_rebalance_cb;
    conf->set("rebalance_cb", &my_rebalance_cb, errstr);

    conf->set("group.id", groupid, errstr);

    RdKafka::KafkaConsumer m_consumer = RdKafka::KafkaConsumer::create(conf, errstr);
    if(!m_consumer)
    {
        std::cerr << "Failed to create consumer: " <<
            errstr << std::endl;
    }

    RdKafka::ErrorCode resp = m_consumer->subscribe(topics);
    if (resp != RdKafka::ERR_NO_ERROR)
    {
        std::cerr << "Failed to subscribe to " << topics.size() << " topics: "
              << RdKafka::err2str(resp) << std::endl;
        return false;
    }

    while(true)
    {
        RdKafka::Message *msg = m_consumer->consume(m_topic, partition, 500);
        msg_consume(msg, NULL);
        delete msg;
    }

    m_consumer->stop();
    delete m_consumer;
    delete conf;
    delete tconf;
    delete m_consumer;

    return true;
}
</code></pre>

#### 2. RdKafka::Consumer
Consumer使用起来稍微麻烦，需要初始化Consumer、Topic和Conf,配置brokers、groupid、partition、offset等字段就可以使用。
##### 2.1. partition
int32_t partition = RdKafka::Topic::PARTITION_UA; // -1
运行时需要赋值指向   

#####2.2. offset
int64_t start_offset = RdKafka::Topic::OFFSET_END; // OFFSET_BEGINNING is antoher choice

例子代码：
<pre><code>
#include &lt;librdkafka/rdkafkacpp.h>

void msg_consume(RdKafka::Message* message, void* opaque)
{
    switch (message->err()) {
        case RdKafka::ERR__TIMED_OUT:
            break;

        case RdKafka::ERR_NO_ERROR:
        {
            // message from kafka
            string valStr(static_cast<char*>(message->payload()),
                static_cast<int>(message->len()));
        }
            break;

        case RdKafka::ERR__PARTITION_EOF:

            break;

        case RdKafka::ERR__UNKNOWN_TOPIC:
        case RdKafka::ERR__UNKNOWN_PARTITION:
            std::cerr << "Consume failed: " << message->errstr() << std::endl;
            break;

        default:
            std::cerr << "Consume failed: " << message->errstr() << std::endl;
    }
}

bool process(const string &topic_str, const string &brokers, const string &groupid)
{
    string errstr;
    int32_t partition = RdKafka::Topic::PARTITION_UA;
    int64_t start_offset = RdKafka::Topic::OFFSET_END;

    std::vector<std::string> topics;
    topics.push_back(topic_str);

    RdKafka::Conf conf = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
    RdKafka::Conf tconf = RdKafka::Conf::create(RdKafka::Conf::CONF_TOPIC);

    conf->set("enable.auto.commit", "true", errstr);
    conf->set("metadata.broker.list", brokers, errstr);

    conf->set("default_topic_conf", tconf, errstr);

    conf->set("group.id", groupid, errstr);

    RdKafka::Consumer m_consumer = RdKafka::KafkaConsumer::create(conf, errstr);
    if(!m_consumer)
    {
        std::cerr << "Failed to create consumer: " <<
            errstr << std::endl;
    }

    RdKafka::Topic m_topic = RdKafka::Topic::create(m_consumer, topics[0], tconf, errstr);
    if (!m_topic)
    {
      std::cerr << "Failed to create topic: " << errstr << std::endl;
      return false;
    }

    std::cout << "% Created topic " << m_topic->name() << std::endl;
    // set partition
    partition = 0;
    RdKafka::ErrorCode resp = m_consumer->start(m_topic, partition, start_offset);
    if (resp != RdKafka::ERR_NO_ERROR)
    {
        std::cerr << "Failed to subscribe to " << topics.size() << " topics: "
              << RdKafka::err2str(resp) << std::endl;
        return false;
    }

    while(true)
    {
        RdKafka::Message *msg = m_consumer->consume(m_topic, partition, 500);
        msg_consume(msg, NULL);
        delete msg;
    }

    m_consumer->stop(m_topic, partition, 500));
    delete m_topic;
    delete m_consumer;
    delete conf;
    delete tconf;
    delete m_consumer;

    return true;
}
</code></pre>
